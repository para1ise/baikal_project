{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules and init in gee\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "from typing import Dict, Any, List, Union, Sequence, Tuple\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "from scipy.stats.mstats import theilslopes\n",
    "from hampel import hampel\n",
    "\n",
    "\n",
    "plt.rcParams['axes.edgecolor'] = 'blue'\n",
    "plt.rcParams['figure.figsize'] = [14, 7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### caclulation statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_log(in_situ: Sequence[float], pred: Sequence[float]) -> float:\n",
    "    \"\"\"Вычисляет среднюю абсолютную ошибку в логарифмическом масштабе (MAE_log).\n",
    "    \n",
    "    Args:\n",
    "        in_situ: Истинные значения (измеренные данные)\n",
    "        pred: Предсказанные значения\n",
    "        \n",
    "    Returns:\n",
    "        MAE_log: Значение метрики, рассчитанной как среднее абсолютное отклонение логарифмов\n",
    "    \"\"\"\n",
    "    \n",
    "    res = 0\n",
    "    y_pred_pos = np.maximum(np.array(pred), 0.01)\n",
    "    for i, ai in enumerate(in_situ):\n",
    "        res += abs(np.log10(y_pred_pos[i]) - np.log10(ai))\n",
    "    res /= len(in_situ)\n",
    "    return 10 ** res\n",
    "\n",
    "\n",
    "def bias_log(in_situ: Sequence[float], pred: Sequence[float]) -> float:\n",
    "    \"\"\"Вычисляет систематическую ошибку в логарифмическом масштабе (BIAS_log).\n",
    "    \n",
    "    Args:\n",
    "        in_situ: Истинные значения\n",
    "        pred: Предсказанные значения\n",
    "        \n",
    "    Returns:\n",
    "        BIAS_log: Среднее значение разности логарифмов предсказаний и истинных значений\n",
    "    \"\"\"\n",
    "    \n",
    "    res = 0\n",
    "    y_pred_pos = np.maximum(np.array(pred), 0.01)\n",
    "    for i, ai in enumerate(in_situ):\n",
    "        res += np.log10(y_pred_pos[i]) - np.log10(ai)\n",
    "    res /= len(in_situ)\n",
    "    return 10 ** res\n",
    "\n",
    "\n",
    "def r2_cov(y: Sequence[float], y_pred: Sequence[float]) -> float:\n",
    "    \"\"\"Вычисляет коэффициент детерминации R² через ковариацию.\n",
    "    \n",
    "    Args:\n",
    "        y: Истинные значения\n",
    "        y_pred: Предсказанные значения\n",
    "        \n",
    "    Returns:\n",
    "        R²: Значение метрики от 0 до 1, где 1 - идеальное совпадение\n",
    "    \"\"\"\n",
    "    \n",
    "    y = np.array(y)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_bar = y.mean()\n",
    "    y_pred_bar = y_pred.mean()\n",
    "    return np.pow(np.sum((y - y_bar) * (y_pred - y_pred_bar)) /\n",
    "                  np.sqrt(np.sum(np.pow(y - y_bar, 2)) * np.sum(np.pow(y_pred - y_pred_bar, 2))), 2)\n",
    "\n",
    "\n",
    "def bias(in_situ: Sequence[float], pred: Sequence[float]) -> float:\n",
    "    \"\"\"Вычисляет систематическую ошибку (BIAS).\n",
    "    \n",
    "    Args:\n",
    "        in_situ: Истинные значения\n",
    "        pred: Предсказанные значения\n",
    "        \n",
    "    Returns:\n",
    "        BIAS: Среднее значение разности между предсказаниями и истинными значениями\n",
    "    \"\"\"\n",
    "    \n",
    "    res = 0\n",
    "    for i, ai in enumerate(in_situ):\n",
    "        res += (pred[i] - ai)\n",
    "    return res / len(in_situ)\n",
    "\n",
    "\n",
    "def sen_slope(list_in_situ: Sequence[float], list_calc: Sequence[float]) -> float:\n",
    "    \"\"\"Вычисляет наклон по Тейлу-Сену между двумя наборами данных.\n",
    "    \n",
    "    Args:\n",
    "        list_in_situ: Первый набор данных\n",
    "        list_calc: Второй набор данных\n",
    "        \n",
    "    Returns:\n",
    "        slope: Наклон регрессии Тейла-Сена\n",
    "    \"\"\"\n",
    "    \n",
    "    return theilslopes(list_in_situ, list_calc).slope\n",
    "\n",
    "\n",
    "def std(in_situ: Sequence[float], pred: Sequence[float]) -> float:\n",
    "    \"\"\"Вычисляет стандартное отклонение разности предсказаний и истинных значений.\n",
    "    \n",
    "    Args:\n",
    "        in_situ: Истинные значения\n",
    "        pred: Предсказанные значения\n",
    "        \n",
    "    Returns:\n",
    "        std: Стандартное отклонение разности\n",
    "    \"\"\"\n",
    "    \n",
    "    return np.std(np.array(pred) - np.array(in_situ))\n",
    "\n",
    "\n",
    "def calculate_statistics(list_in_situ: Sequence[float], list_calc: Sequence[float]) -> List[float]:\n",
    "    \"\"\"Рассчитывает набор статистических метрик для оценки качества предсказаний.\n",
    "    \n",
    "    Args:\n",
    "        list_in_situ: Истинные значения\n",
    "        list_calc: Предсказанные значения\n",
    "        \n",
    "    Returns:\n",
    "        Список метрик в следующем порядке:\n",
    "        [R², BIAS_log, BIAS, MAE_log, MAE, RMSE, STD, Sen_slope, MAPE]\n",
    "        где:\n",
    "        - R²: Коэффициент детерминации\n",
    "        - BIAS_log: Систематическая ошибка в логарифмическом масштабе\n",
    "        - BIAS: Среднее отклонение\n",
    "        - MAE_log: Средняя абсолютная ошибка в логарифмическом масштабе\n",
    "        - MAE: Средняя абсолютная ошибка\n",
    "        - RMSE: Корень из среднеквадратичной ошибки\n",
    "        - STD: Стандартное отклонение разности\n",
    "        - Sen_slope: Наклон по Тейлу-Сену\n",
    "        - MAPE: Средняя абсолютная процентная ошибка (%)\n",
    "    \"\"\"\n",
    "    \n",
    "    arr = [r2_cov(list_in_situ, list_calc), \n",
    "           bias_log(list_in_situ, list_calc),\n",
    "           bias(list_in_situ, list_calc), \n",
    "           mae_log(list_in_situ, list_calc), \n",
    "           mean_absolute_error(list_in_situ, list_calc),\n",
    "           np.sqrt(mean_squared_error(list_in_situ, list_calc)), \n",
    "           std(list_in_situ, list_calc),\n",
    "           sen_slope(list_calc, list_in_situ), \n",
    "           mean_absolute_percentage_error(list_in_situ, list_calc) * 100]\n",
    "    return list(map(lambda x: round(x, 3), arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### draw and estimated chl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_graphic(list1: Sequence[float], list2: Sequence[float], name_algo: str, save_folder: str = None) -> float:\n",
    "    \"\"\"\n",
    "    Строит регрессионный график с линейной регрессией и оценочную функцию Тейла-Сена.\n",
    "    \n",
    "    Args:\n",
    "        list1: Истинные значения (измеренные данные)\n",
    "        list2: Предсказанные значения\n",
    "        name_algo: Название алгоритма для подписи графика\n",
    "        save_folder: Папка для сохранения графика (по умолчанию None - отображает график)\n",
    "    \n",
    "    Returns:\n",
    "        float: Стандартное отклонение разности между истинными и предсказанными значениями\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: Если длины входных последовательностей не совпадают\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(list1) != len(list2):\n",
    "        raise ValueError(\"Длины входных последовательностей должны совпадать\")\n",
    "    \n",
    "    x = np.array(copy.deepcopy(list1)).reshape((-1, 1))\n",
    "    y1 = np.array(copy.deepcopy(list2))\n",
    "    \n",
    "    model = LinearRegression().fit(x, y1)\n",
    "    x_dots = np.linspace(x.min(), x.max(), 100).reshape((-1, 1))\n",
    "    y_pred = model.predict(x_dots)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.scatter(x, y1, c=[(0.7, 0.2, 0.9)], s=150,\n",
    "                edgecolor='black', linewidth=1.5, alpha=0.9, \n",
    "                marker='o', zorder=3, label='Измеренные данные')\n",
    "    \n",
    "    plt.plot(x_dots, y_pred, 'b', label='Линейная регрессия')\n",
    "    \n",
    "    st = theilslopes(list2, list1)\n",
    "    plt.plot(x_dots, st.slope * x_dots + st.intercept, color='green', label='Оценочная функция Тейла-Сена')\n",
    "    \n",
    "    plt.plot(x_dots, x_dots, '--', color='black', label='1:1 линия')\n",
    "    \n",
    "    plt.xlabel(f\"in_situ, мкг/л\\nN = {len(list1)}, Наклон Тейла-Сена = {st.slope:.3f}\", fontsize=16, labelpad=10)\n",
    "    plt.ylabel(f\"{name_algo}, мкг/л\", fontsize=16, labelpad=10)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_folder:\n",
    "        os.makedirs(f\"graphics/{save_folder}\", exist_ok=True)\n",
    "        filename = f\"{name_algo}.png\"\n",
    "        save_path = os.path.join(f\"graphics/{save_folder}\", filename)\n",
    "        plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "    \n",
    "    return round(np.std(np.array(list2) - np.array(list1)), 3)\n",
    "\n",
    "\n",
    "def calculate_statistics_and_draw_graphic(df_in_situ: pd.DataFrame, **kwargs: Dict[str, Dict[Any, float]]) -> Dict[str, List[Any]]:\n",
    "    \"\"\"\n",
    "    Рассчитывает статистики и строит графики для множества алгоритмов.\n",
    "    \n",
    "    Args:\n",
    "        df_in_situ: DataFrame с истинными значениями (столбец 'CHL')\n",
    "        **kwargs: Словари с результатами алгоритмов в формате {имя_алгоритма: {ключ: значение}}\n",
    "    \n",
    "    Returns:\n",
    "        Dict[str, List[Any]]: Словарь со статистиками по каждому алгоритму, содержащий:\n",
    "            - [R², BIAS_log, BIAS, MAE_log, MAE, RMSE, STD, Sen_slope, MAPE]\n",
    "            - Количество точек\n",
    "            - Фильтрованные истинные значения\n",
    "            - Фильтрованные предсказанные значения\n",
    "    \"\"\"\n",
    "    \n",
    "    dict_in_situ = {key: value for key, value in zip(df_in_situ.index.to_list(), df_in_situ['CHL'].to_list())}\n",
    "    statistics = dict()\n",
    "    \n",
    "    for algo_name, algo_dict in kwargs.items():\n",
    "        tmp_copy_calc = copy.deepcopy(algo_dict)\n",
    "        \n",
    "        for k, v in tmp_copy_calc.items():\n",
    "            if v is None or v <= 0 or np.isnan(v) or abs(dict_in_situ[k] - tmp_copy_calc[k]) > 100:\n",
    "                del algo_dict[k]\n",
    "        \n",
    "        tmp_copy_in_situ = copy.deepcopy(dict_in_situ)\n",
    "        for k in list(tmp_copy_in_situ.keys()):\n",
    "            if k not in algo_dict:\n",
    "                del tmp_copy_in_situ[k]\n",
    "        \n",
    "        in_situ_values = list(tmp_copy_in_situ.values())\n",
    "        calc_chl = list(algo_dict.values())\n",
    "        \n",
    "        if len(calc_chl) > 3:\n",
    "            statistics[algo_name] = [*calculate_statistics(in_situ_values, calc_chl), \n",
    "                                   len(calc_chl), \n",
    "                                   tmp_copy_in_situ, \n",
    "                                   algo_dict]\n",
    "            \n",
    "            draw_graphic(in_situ_values, calc_chl, algo_name, save_folder=\"regional\")\n",
    "        else:\n",
    "            print(f\"Недостаточно данных для алгоритма {algo_name} (количество точек = {len(calc_chl)})\")\n",
    "    \n",
    "    return statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### formulae in articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Beck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beck(values: dict):\n",
    "    ndci = (values['B5'] - values['B4']) / (values['B5'] + values['B4']) \n",
    "    flh_violet = values['B3'] - (values['B4'] + ((665 - 560.5) / (665 - 490.5) * (values['B2'] - values['B4'])))\n",
    "    _2bda = values['B5'] / values['B4']\n",
    "    _3bda = ((1 / values['B4']) - (1 / values['B5'])) * values['B8A']\n",
    "    \n",
    "    ndci_chl = None if (_ndci := 0.388 * ndci - 18.844) < 0 else _ndci\n",
    "    flh_violet_chl = None if (_flh_violet_chl := -0.033 * flh_violet + 53.064) < 0 else _flh_violet_chl\n",
    "    _2bda_chl = None if (__2bda_chl := _2bda * 86.148 - 51.94) < 0 else __2bda_chl\n",
    "    _3bda_chl = None if (__3bda_chl := 156.286 * _3bda + 35.982) < 0 else __3bda_chl\n",
    "    return ndci_chl, flh_violet_chl, _2bda_chl, _3bda_chl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Molkov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def molkov_linear(x, a, b):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    return None if x is None or (_ := a * x + b) < 0 else _\n",
    "    \n",
    "    \n",
    "def molkov_poly(x, a, b, c):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "    return None if x is None or (_ := a * np.pow(x, 2) + b * x + c) < 0 else _ \n",
    "\n",
    "\n",
    "def molkov_exp(x, a, b):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    return None if x is None else a * np.exp(b * x)\n",
    "    \n",
    "    \n",
    "def molkov_power1(x, a, b):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    return None if x is None else a * np.pow(x, b)\n",
    "    \n",
    "\n",
    "def molkov_power2(x, a, b, c):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "    return None if (x is None) or np.any(a * x + b < 0) else np.pow((a * x + b), c)\n",
    "        \n",
    "\n",
    "def molkov(values: dict) -> tuple:\n",
    "    \"\"\"For each values of bands calculate indecies, which looks like lists [lin, poly, exp, p1, p2]\n",
    "\n",
    "    Returns:\n",
    "        tuple of lists: dim = 8: ndci_list, _2bda_list, _3bda_list, ph_list, \\n\n",
    "        _2b_linear_result, _2b_poly_result, ndci_linear_result, ndci_poly_result\n",
    "    \"\"\"\n",
    "    \n",
    "    ndci = (values['B5'] - values['B4']) / (values['B5'] + values['B4'])\n",
    "    _2bda = values['B5'] / values['B4']\n",
    "    _3bda = ((1 / values['B4']) - (1 / values['B5'])) * values['B6']\n",
    "    ph = values['B5'] - (values['B6'] + values['B4']) / 2\n",
    "    \n",
    "    ndci_list, _2bda_list, _3bda_list, ph_list = np.zeros(5, dtype=np.float64), np.zeros(5, dtype=np.float64), \\\n",
    "        np.zeros(5, dtype=np.float64), np.zeros(5, dtype=np.float64)\n",
    "    \n",
    "    ndci_list[0], _2bda_list[0], _3bda_list[0], ph_list[0] = molkov_linear(ndci, 90.101, 13.75), \\\n",
    "        molkov_linear(_2bda, 24.463, -8.356), molkov_linear(_3bda, 35.812, 19.24), molkov_linear(ph, 2340.123, 9.185)\n",
    "    \n",
    "    ndci_list[1], _2bda_list[1], _3bda_list[1], ph_list[1] = molkov_poly(ndci, 88.757, 52.715, 15.06), \\\n",
    "        molkov_poly(_2bda, -2.155, 33.034, -15.59), molkov_poly(_3bda, -10.227, 52.867, 16.91), molkov_poly(ph, -17567.0, 2814.313, 7.11)\n",
    "    \n",
    "    ndci_list[2], _2bda_list[2], _3bda_list[2], ph_list[2] = molkov_exp(ndci, 16.365, 2.754), \\\n",
    "        molkov_exp(_2bda, 12.546, 0.526), molkov_exp(_3bda, 25.114, 0.554), molkov_exp(ph, 17.808, 52.313)\n",
    "    \n",
    "    ndci_list[3], _2bda_list[3], _3bda_list[3], ph_list[3] = None, molkov_power1(_2bda, 17.346, 1.198), \\\n",
    "        None, molkov_power1(ph, 890.568, 0.708)\n",
    "    \n",
    "    ndci_list[4], _2bda_list[4], _3bda_list[4], ph_list[4] = molkov_power2(ndci, 6.251, 3.359, 2.217), \\\n",
    "        molkov_power2(_2bda, 96.806, -61.71, 0.764), molkov_power2(_3bda, 4373.068, 296.6, 0.479), molkov_power2(ph, 7834.173, 8.051, 0.789)\n",
    "    \n",
    "    _2b_linear_result = molkov_linear(_2bda, 64.536, -57.8)\n",
    "    _2b_poly_result = molkov_poly(_2bda, -73.669, 252.808, -176.68)\n",
    "    ndci_linear_result = molkov_linear(ndci, 167.293, 4.756)\n",
    "    ndci_poly_result = molkov_poly(ndci, -300.26, 235.556, 1.586)\n",
    "    return ndci_list, _2bda_list, _3bda_list, ph_list, \\\n",
    "        _2b_linear_result, _2b_poly_result, ndci_linear_result, ndci_poly_result\n",
    "\n",
    "\n",
    "def convert_molkov_dict(index_dict: dict) -> tuple:\n",
    "    \"\"\"For each pair flatten lists to dict: id: [0, 1, 2, ...] -> dict(id: 0), dict(id: 1), ...\n",
    "\n",
    "    Returns:\n",
    "        tuple of dicts\n",
    "    \"\"\"\n",
    "    _0, _1, _2, _3, _4 = dict(), dict(), dict(), dict(), dict()\n",
    "    for k, v in index_dict.items():\n",
    "        _0[k] = v[0]\n",
    "        _1[k] = v[1]\n",
    "        _2[k] = v[2]\n",
    "        _3[k] = v[3]\n",
    "        _4[k] = v[4]\n",
    "    return _0, _1, _2, _3, _4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def li_candidate13(x, a0, a1, a2, a3, a4):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x: np.log10(values['B2'] / values['B3'])\n",
    "    \"\"\"\n",
    "    return np.pow(10, a0 + a1 * x + a2 * np.pow(x, 2) + a3 * np.pow(x, 3) + a4 * np.pow(x, 4))\n",
    "\n",
    "\n",
    "def li_candidate(values: dict):\n",
    "    \"\"\"\n",
    "    ndci = None if values['B5'] < values['B4'] else (values['B5'] - values['B4']) / (values['B5'] + values['B4']) \n",
    "    _2bda1 = values['B6'] / values['B5']\n",
    "    _2bda2 = values['B5'] / values['B4']\n",
    "    _3bda = None if values['B5'] < values['B4'] else ((1 / values['B4']) - (1 / values['B5'])) * values['B6']\n",
    "    \"\"\"\n",
    "    \n",
    "    chl11 = None if (__chl11 := 136.3 * (values['B6'] / values['B4']) - 16.2) < 0 else __chl11\n",
    "    \n",
    "    chl12 = None if (__chl12 := 25.28 * (_chl12 := values['B5'] / values['B4'])**2 + 14.85 * _chl12 - 15.18) < 0 else __chl12\n",
    "    \n",
    "    chl13 = np.pow(10, 0.2389 - 1.9369 * (_chl13 := np.log10(values['B2'] / values['B3'])) +\n",
    "                   1.7627 * _chl13**2 - 3.0777 * _chl13**3 - 0.1054 * _chl13**4)\n",
    "    \n",
    "    \n",
    "    chl211 = None if \\\n",
    "        (__chl211 := 117.42 * ((1 / values['B4']) - (1 / values['B5'])) * values['B6'] + 23.09) < 0 else __chl211\n",
    "        \n",
    "    chl212 = None if \\\n",
    "        (__chl212 := 232.329 * ((1 / values['B4']) - (1 / values['B5'])) * values['B6'] + 23.174) < 0 else __chl212\n",
    "        \n",
    "    chl213 = None if \\\n",
    "        (__chl213 := 315.50 * (_chl213 := ((1 / values['B4'] - 1 / values['B5']) * values['B6']))**2 +\n",
    "                      215.95 * _chl213 + 25.66) < 0 else __chl213\n",
    "        \n",
    "    chl22 = None if values['B6'] == values['B5'] or (__chl22 := \\\n",
    "        161.24 * (((1 / values['B4']) - (1 / values['B5'])) / ((1 / values['B6']) - (1 / values['B5']))) + 28.04) < 0 else __chl22\n",
    "    return chl11, chl12, chl13, chl211, chl212, chl213, chl22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Makwinja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makwinja(values: dict):\n",
    "    ndci = (values['B5'] - values['B4']) / (values['B5'] + values['B4'])\n",
    "    return None if (_ndci := 431.98 * ndci**2 + 104 * ndci + 9.547) < 0 else _ndci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boldanova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boldanova(values: dict):\n",
    "    boldanova_b3 = None if (_boldanova_b3 := 3635.4 * (values['B3'])**2 - 185.7 * values['B3'] + 3.5) < 0 else _boldanova_b3\n",
    "    return boldanova_b3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Karimi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def karimi(values: dict):\n",
    "    _2bda = None if values['B4'] == 0 else \\\n",
    "        np.exp(3.4 * (__2bda := values['B5'] / values['B4'])**2 - 6.6 * __2bda + 4.9)\n",
    "    ndci = np.exp(5.83 * (_ndci := (values['B5'] - values['B4']) / (values['B5'] + values['B4']))**2 + 0.075 * _ndci + 1.72)\n",
    "    _3bda = np.exp(2.6 * (__3bda := ((1 / values['B4']) - (1 / values['B5'])) * values['B8A'])**2 - 0.2 * __3bda + 1.74)\n",
    "    return _2bda, ndci, _3bda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### O'Reilly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oc3_msi(x, a0, a1, a2, a3, a4):\n",
    "    return np.pow(10, a0 + a1 * x + a2 * np.pow(x, 2) + a3 * np.pow(x, 3) + a4 * np.pow(x, 4))\n",
    "\n",
    "\n",
    "def oreilly(values: dict):\n",
    "    oc3 = np.pow(10., 0.30963 - \\\n",
    "        2.40052 * (_oc3 := np.log10(max(values['B1'], values['B2']) / values['B3'])) + \\\n",
    "            1.28932 * _oc3**2 + 0.52802 * _oc3**3 - 1.33825 * _oc3**4)\n",
    "    return oc3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(dict_stats: Dict[str, Dict[str, float]], df: pd.DataFrame, article: str) -> Dict[str, List[Union[float, int, Dict, Any]]]:\n",
    "    \"\"\"\n",
    "    Обрабатывает данные по заданному алгоритму, строит графики и рассчитывает статистику.\n",
    "    \n",
    "    Args:\n",
    "        dict_stats (Dict[str, Dict[str, float]]): Словарь со спектральными данными для обработки.\n",
    "            Ключи - идентификаторы образцов, значения - словари с ключами 'B2', 'B3', 'B4', 'B5', 'B8A' и др.\n",
    "        df (pd.DataFrame): Входной DataFrame с истинными значениями (столбец 'CHL').\n",
    "        article (str): Идентификатор алгоритма для обработки. Допустимые значения:\n",
    "            \"beck\", \"molkov\", \"li\", \"makwinja\", \"boldanova\", \"karimi\", \"oreilly\"\n",
    "    \n",
    "    Returns:\n",
    "        Dict[str, List[Union[float, int, Dict, Any]]]: Словарь, где ключи - названия алгоритмов, а значения - списки со статистиками:\n",
    "            [R², BIAS_log, BIAS, MAE_log, MAE, RMSE, STD, Sen_slope, MAPE, count, in_situ_dict, calc_dict]\n",
    "            Подробности см. в докстринге calculate_statistics_and_draw_graphic\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: Если указан неверный идентификатор алгоритма (article)\n",
    "    \"\"\"\n",
    "    \n",
    "    statistics = {}\n",
    "    \n",
    "    match article:\n",
    "        case \"beck\":\n",
    "            beck_ndci_chl, beck_flh_violet_chl, beck_2bda_chl, beck_3bda_chl = defaultdict(dict), defaultdict(dict), defaultdict(dict), defaultdict(dict)\n",
    "            \n",
    "            for k, v in dict_stats.items():\n",
    "                beck_ndci_chl[k], beck_flh_violet_chl[k], beck_2bda_chl[k], beck_3bda_chl[k] = beck(v)\n",
    "            \n",
    "            statistics.update(calculate_statistics_and_draw_graphic(df, \n",
    "                beck_ndci=beck_ndci_chl, \n",
    "                beck_flh_violet=beck_flh_violet_chl,\n",
    "                beck_2bda=beck_2bda_chl, \n",
    "                beck_3bda=beck_3bda_chl))\n",
    "        \n",
    "        case \"molkov\":\n",
    "            molkov_ndci, molkov_2bda, molkov_3bda, molkov_ph = {}, {}, {}, {}\n",
    "            molkov_2b_linear_result, molkov_2b_poly_result = {}, {}\n",
    "            molkov_ndci_linear_result, molkov_ndci_poly_result = {}, {}\n",
    "            \n",
    "            for k, v in dict_stats.items():\n",
    "                molkov_ndci[k], molkov_2bda[k], molkov_3bda[k], molkov_ph[k], \\\n",
    "                molkov_2b_linear_result[k], molkov_2b_poly_result[k], \\\n",
    "                molkov_ndci_linear_result[k], molkov_ndci_poly_result[k] = molkov(v)\n",
    "            \n",
    "            molkov_ndci_list = convert_molkov_dict(molkov_ndci)\n",
    "            molkov_2bda_list = convert_molkov_dict(molkov_2bda)\n",
    "            molkov_3bda_list = convert_molkov_dict(molkov_3bda)\n",
    "            molkov_ph_list = convert_molkov_dict(molkov_ph)\n",
    "            \n",
    "            statistics.update(calculate_statistics_and_draw_graphic(df,\n",
    "                molkov_ndci_linear=molkov_ndci_list[0], molkov_ndci_poly=molkov_ndci_list[1],\n",
    "                molkov_ndci_exp=molkov_ndci_list[2], molkov_ndci_power2=molkov_ndci_list[4],\n",
    "                \n",
    "                molkov_2b_linear=molkov_2bda_list[0], molkov_2b_poly=molkov_2bda_list[1],\n",
    "                molkov_2b_exp=molkov_2bda_list[2], molkov_2b_power1=molkov_2bda_list[3],\n",
    "                molkov_2b_power2=molkov_2bda_list[4],\n",
    "                \n",
    "                molkov_3b_linear=molkov_3bda_list[0], molkov_3b_poly=molkov_3bda_list[1],\n",
    "                molkov_3b_exp=molkov_3bda_list[2], molkov_3b_power2=molkov_3bda_list[4],\n",
    "                \n",
    "                molkov_ph_linear=molkov_ph_list[0], molkov_ph_poly=molkov_ph_list[1],\n",
    "                molkov_ph_exp=molkov_ph_list[2], molkov_ph_power1=molkov_ph_list[3],\n",
    "                molkov_ph_power2=molkov_ph_list[4],\n",
    "                \n",
    "                molkov_2b_linear_result=molkov_2b_linear_result, \n",
    "                molkov_2b_poly_result=molkov_2b_poly_result,\n",
    "                molkov_ndci_linear_result=molkov_ndci_linear_result, \n",
    "                molkov_ndci_poly_result=molkov_ndci_poly_result))\n",
    "        \n",
    "        case \"li\":\n",
    "            li_candidate11, li_candidate12, li_candidate13 = {}, {}, {}\n",
    "            li_candidate211, li_candidate212, li_candidate213, li_candidate22 = {}, {}, {}, {}\n",
    "            \n",
    "            for k, v in dict_stats.items():\n",
    "                li_candidate11[k], li_candidate12[k], li_candidate13[k], li_candidate211[k], li_candidate212[k], \\\n",
    "                li_candidate213[k], li_candidate22[k] = li_candidate(v)\n",
    "                print(k, li_candidate13[k], df.loc[k, 'CHL'])\n",
    "    \n",
    "            statistics.update(calculate_statistics_and_draw_graphic(df,\n",
    "                li11=li_candidate11, li12=li_candidate12,\n",
    "                li13=li_candidate13, li211=li_candidate211,\n",
    "                li212=li_candidate212, li213=li_candidate213,\n",
    "                li22=li_candidate22))\n",
    "        \n",
    "        case \"makwinja\":\n",
    "            makwinja_ndci = {}\n",
    "            \n",
    "            for k, v in dict_stats.items():\n",
    "                makwinja_ndci[k] = makwinja(v)\n",
    "            \n",
    "            statistics.update(calculate_statistics_and_draw_graphic(df, \n",
    "                makwinja_ndci=makwinja_ndci))\n",
    "        \n",
    "        case \"boldanova\":\n",
    "            boldanova_b3 = {}\n",
    "            for k, v in dict_stats.items():\n",
    "                boldanova_b3[k] = boldanova(v)\n",
    "            \n",
    "            statistics.update(calculate_statistics_and_draw_graphic(df, \n",
    "                boldanova_b3=boldanova_b3))\n",
    "        \n",
    "        case \"karimi\":\n",
    "            karimi_2bda, karimi_ndci, karimi_3bda = {}, {}, {}\n",
    "            for k, v in dict_stats.items():\n",
    "                karimi_2bda[k], karimi_ndci[k], karimi_3bda[k] = karimi(v)\n",
    "            \n",
    "            statistics.update(calculate_statistics_and_draw_graphic(df, \n",
    "                karimi_2bda=karimi_2bda, karimi_ndci=karimi_ndci,\n",
    "                karimi_3bda=karimi_3bda))\n",
    "        \n",
    "        case \"oreilly\":\n",
    "            oreilly_oc3 = {}\n",
    "            for k, v in dict_stats.items():\n",
    "                oreilly_oc3[k] = oreilly(v)\n",
    "            \n",
    "            statistics.update(calculate_statistics_and_draw_graphic(df, \n",
    "                oc3_msi=oreilly_oc3))\n",
    "        \n",
    "        case _:\n",
    "            raise ValueError(f\"Неизвестный алгоритм: {article}. \"\n",
    "                           \"Допустимые значения: beck, molkov, li, makwinja, boldanova, karimi, oreilly\")\n",
    "    \n",
    "    return statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_stat_dict_to_list_stat_and_values(arg_dict):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        arg_dict: {\"name_algo1\": [r2, bias, mae, n, {id: in situ}, {id: calculated}], \"name_algo2\": ...}\n",
    "    \n",
    "    Return: [{statustics (4 keys)}, {\"name_algo\" : [{id: in situ}, {id: calculated}]}]\n",
    "    \"\"\"\n",
    "    \n",
    "    statistics_dict = {}\n",
    "    data_dict = {}\n",
    "    for algo_name, algo_list in arg_dict.items():\n",
    "        statistics_dict[algo_name] = algo_list[:-2]\n",
    "        data_dict[algo_name] = [algo_list[-2], algo_list[-1]]\n",
    "    return [statistics_dict, data_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv(\"../data/processed/chl_data.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rrs = pd.read_csv(\"../data/processed/rrs_data.csv\", index_col=0)\n",
    "dict_stats = df_rrs.T.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### graphics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Beck (USA, 2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beck_data = main(dict_stats, df_all, \"beck\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Molkov (Russia, 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molkov_data = main(dict_stats, df_all, \"molkov\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Li (China, 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li_candidate_data = main(dict_stats, df_all, \"li\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Makwinja (Africa-Japan, 2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "makwinja_data = main(dict_stats, df_all, \"makwinja\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boldanova (Russia, 2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boldanova_data = main(dict_stats, df_all, \"boldanova\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Karimi (Iran, 2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "karimi_data = main(dict_stats, df_all, \"karimi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### O'Reilly (USA, 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oreilly_data = main(dict_stats, df_all, \"oreilly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['R^2', 'Bias_log', 'Bias', 'MAE_log', 'MAE',\t'RMSE', 'std', 'SS', 'MAPE', 'N']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Beck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beck_stat = pd.DataFrame.from_dict(convert_stat_dict_to_list_stat_and_values(beck_data)[0], orient='index', columns=columns)\n",
    "beck_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Molkov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molkov_stat = pd.DataFrame.from_dict(convert_stat_dict_to_list_stat_and_values(molkov_data)[0], orient='index', columns=columns)\n",
    "molkov_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li_candidate_stat = pd.DataFrame.from_dict(convert_stat_dict_to_list_stat_and_values(li_candidate_data)[0], orient='index', columns=columns)\n",
    "li_candidate_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Makwinja "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "makwinja_stat = pd.DataFrame.from_dict(convert_stat_dict_to_list_stat_and_values(makwinja_data)[0], orient='index', columns=columns)\n",
    "makwinja_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boldanova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boldanova_stat = pd.DataFrame.from_dict(convert_stat_dict_to_list_stat_and_values(boldanova_data)[0], orient='index', columns=columns)\n",
    "boldanova_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Karimi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "karimi_stat = pd.DataFrame.from_dict(convert_stat_dict_to_list_stat_and_values(karimi_data)[0], orient='index', columns=columns)\n",
    "karimi_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### O'Reilly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oreilly_stat = pd.DataFrame.from_dict(convert_stat_dict_to_list_stat_and_values(oreilly_data)[0], orient='index', columns=columns)\n",
    "oreilly_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers(df_init: pd.DataFrame, threshold=3, n_sigma=1.1, window_size=3, **kwargs) -> Tuple[pd.DataFrame, Dict[str, List[Any]], Dict[str, List[int]]]:\n",
    "    \"\"\"\n",
    "    Обнаруживает выбросы в данных с использованием метода Хампеля и обновляет DataFrame с флагами выбросов.\n",
    "    \n",
    "    Args:\n",
    "        df_init (pd.DataFrame): Исходный DataFrame с данными для анализа\n",
    "        threshold (float, optional): Пороговое значение для начального удаления явных выбросов. Defaults to 3.\n",
    "        n_sigma (float, optional): Количество сигм для определения выбросов в методе Хампеля. Defaults to 1.1.\n",
    "        window_size (int, optional): Размер скользящего окна для метода Хампеля. Defaults to 3.\n",
    "        **kwargs: Словари с результатами алгоритмов в формате {имя_алгоритма: [статистики, истинные_значения, предсказанные_значения]}\n",
    "    \n",
    "    Returns:\n",
    "        Tuple[pd.DataFrame, Dict[str, List[Any]], Dict[str, List[int]]]: Кортеж из трех элементов:\n",
    "            1. df_pred: Обновленный DataFrame с добавленными колонками:\n",
    "               - Предсказанные значения от алгоритмов\n",
    "               - Флаги выбросов (flag_hampel_{алгоритм})\n",
    "            2. stat: Словарь со статистиками по алгоритмам после удаления выбросов\n",
    "            3. indecies_dict: Словарь с индексами обнаруженных выбросов для каждого алгоритма\n",
    "    \n",
    "    Raises:\n",
    "        KeyError: Если в kwargs переданы некорректные данные без истинных/предсказанных значений\n",
    "        ValueError: Если входные данные имеют некорректный формат\n",
    "    \"\"\"\n",
    "    \n",
    "    df_pred = copy.deepcopy(df_init)\n",
    "    stat = dict()\n",
    "    indecies_dict = dict()\n",
    "    \n",
    "    for algo_name, algo_dict in kwargs.items():\n",
    "        try:\n",
    "            in_situ = pd.Series(algo_dict[-2])\n",
    "            predicted = pd.Series(algo_dict[-1])\n",
    "        except (IndexError, TypeError):\n",
    "            raise KeyError(f\"Некорректные данные для алгоритма {algo_name}. Требуются истинные и предсказанные значения\")\n",
    "        \n",
    "        residual = np.abs(in_situ - predicted)\n",
    "        indecies_true = np.array([])\n",
    "        \n",
    "        if len((inds_array := np.where(residual > threshold)[0])):\n",
    "            indecies_true = list(map(lambda t: in_situ.index[t], inds_array))\n",
    "            residual = np.delete(residual, inds_array)\n",
    "        \n",
    "        result = hampel(residual, window_size=window_size, n_sigma=n_sigma)\n",
    "        \n",
    "        indecies = list(np.hstack((\n",
    "            list(map(lambda t: in_situ.index[t], result.outlier_indices)),\n",
    "            indecies_true\n",
    "        )).astype(int))\n",
    "        \n",
    "        indecies_dict[algo_name] = indecies\n",
    "        for i in indecies:\n",
    "            if i in in_situ.index:\n",
    "                in_situ.pop(i)\n",
    "                predicted.pop(i)\n",
    "        \n",
    "        indecies_series = pd.Series({k: True if k in indecies else np.nan for k in indecies})\n",
    "        indecies_series.name = f'flag_hampel_{algo_name}'\n",
    "        \n",
    "        predicted_in_table = pd.Series(algo_dict[-1])\n",
    "        predicted_in_table.name = algo_name\n",
    "        \n",
    "        df_pred = pd.concat([df_pred, predicted_in_table, indecies_series], axis=1)\n",
    "        \n",
    "        in_situ_values = copy.deepcopy(in_situ).to_list()\n",
    "        calc_chl = predicted.to_list()\n",
    "        \n",
    "        if len(calc_chl) > 3:\n",
    "            stat[algo_name] = [*calculate_statistics(in_situ_values, calc_chl), \n",
    "                              len(calc_chl), \n",
    "                              in_situ, \n",
    "                              algo_dict]\n",
    "            draw_graphic(in_situ_values, calc_chl, algo_name, save_folder=\"regional\")\n",
    "        else:\n",
    "            print(f\"Недостаточно данных для алгоритма {algo_name} (количество точек = {len(calc_chl)})\")\n",
    "    \n",
    "    for i in df_pred.index:\n",
    "        if df_pred.loc[i, 'datetime':].isna().sum() == len(kwargs) * 2:\n",
    "            df_pred.drop(labels=[i], inplace=True)\n",
    "    \n",
    "    return df_pred, stat, indecies_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_all_data_best = outliers(df_all, threshold=2,\n",
    "                          li13_clear=li_candidate_data['li13'],\n",
    "                          \n",
    "                          oc3_msi_clear=oreilly_data['oc3_msi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict({k: v[:-2] for k, v in clear_all_data_best[1].items()}, orient='index', columns=columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
